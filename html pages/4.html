<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="../css/fontawesome/css/all.min.css">
    <script src="../js/main.js" defer></script>
    <link rel="stylesheet" href="../css/AI_intro.css"> 
    <meta name="author" content="Saad Al-Shargabi">
    <meta name="description" content="Exploring the ethical dilemmas, bias, and future risks of Artificial General Intelligence (AGI).">
    <title>The AI Compass: Ethics and Future</title>
</head>
<body>
    <header>
        <h1><span class="icon">&#9878;</span> The AI Compass</h1>
        <h2>Ethics, Bias, and Responsibility in the Age of Machines</h2>
        <p>As AI systems become more autonomous and influential, the conversation shifts from "can we build it" to 
            "should we build it?" This field explores the moral frameworks and guidelines necessary to ensure AI benefits all of humanity.</p>
        <hr>
        <nav>
            <h3>&#128220; Sections</h3>
            <ul>
                <li><a href="2.html">Home / History</a></li>
                <li><a href="3.html">Applications Today</a></li>
                <li><a href="#bias">Algorithmic Bias</a></li>
                <li><a href="#accountability">Transparency &amp; Trust</a></li>
                <li><a href="#agi-future">AGI &amp; Existential Risk</a></li>
                <li><a href="5.html">Pioneers</a></li>
                <li><a href="contact.html">Contact Us</a></li>
            </ul>
            <hr>
        </nav>
    </header>

    <section id="bias">
        <h2>The Challenge of Algorithmic Bias</h2>
        <p>AI models are trained on historical data. If that data reflects societal biases (racial, gender, economic),
            the AI will learn and amplify those biases. This leads to unfair outcomes in critical areas like hiring, criminal justice, and loan applications.</p>
        
        <div class="callout-box">
            <p><strong>Garbage In, Garbage Out:</strong> The quality and fairness of an AI model are fundamentally limited by the data it consumes. Addressing bias requires careful data curation and auditing of the model&rsquo;s decision-making process.</p>
        </div>
    </section>

    <hr>

    <section id="accountability">
        <h2>Transparency and Accountability</h2>
        <p>Many deep learning models are &ldquo;black boxes&rdquo;&mdash; even their creators cannot fully explain *why* they arrived at a specific decision. This lack of transparency is a major ethical hurdle. Establishing legal accountability is crucial:</p>
        
        <blockquote cite="Hypothetical Legal Scenario">
            &ldquo;When an autonomous vehicle fails, who is liable? The owner, the programmer, the manufacturer, or the algorithm itself? Clear legal frameworks must be established before full autonomy is adopted.&rdquo;
        </blockquote>
    </section>

    <hr>

    <section id="agi-future">
        <h2>The Search for General AI (AGI)</h2>
        <p>Today, nearly all deployed AI is "Narrow AI (ANI)": highly specialized systems capable of performing one task exceptionally well.
             The ultimate goal is "Artificial General Intelligence (AGI)" &mdash;a machine capable of performing any intellectual task a human can.</p>
        
        <table>
            <thead>
                <tr>
                    <th>Narrow AI (ANI)</th>
                    <th>General AI (AGI)</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Specialized to one domain (e.g., Siri, ChatGPT, Face Recognition).</td>
                    <td>Hypothetical machine with human-level cognitive flexibility.</td>
                </tr>
                <tr>
                    <td>Cannot transfer knowledge to new tasks.</td>
                    <td>Can learn new skills and adapt to any intellectual problem.</td>
                </tr>
            </tbody>
        </table>
        <p>The development of AGI carries immense potential but also significant existential risk, 
            prompting researchers like Nick Bostrom to call for greater control and safety measures.</p>
    </section>

    <footer id="contact">
        <hr>
        <p>These challenges were born from the fundamental discoveries made by the field&rsquo;s founders. <a href="5.html">Meet the great minds who built the foundation.</a></p>
        <p><strong>Created by:</strong> Saad Al-Shagabi</p>
        <p>&copy; 2026 AI Chronicles &mdash; All rights reserved.</p>
    </footer>
</body>
</html>